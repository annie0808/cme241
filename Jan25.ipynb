{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 1.}$ \n",
    "Formulate this problem as a Continuous States, Continuous Actions MDP by specifying itâ€™s State Transitions, Rewards and Discount Factor. \n",
    "The problem then is to find the Optimal Policy.\n",
    "\n",
    "Answer: It is MDP because its current wealth is only determined by the most adjacent wealth. For this question, the state is $S_t = (t, W_t)$. The action is the allocation of wealth at $t=0,1,...,T-1$. It can be denoted by $x_t$, which is the allocated risky asset. The policy is $\\pi((t,W_t))=x_t.$ The state transition is $W_{t+1} = x_t(1+R)+(W_t-x_t)(1+r),$ where $R~N(\\mu, \\sigma^2)$ is the random rate of return at single time step. The reward is 0 at $t=0,1,...,T-1.$ At terminal time step $T$ is $U(W_T).$ The discount factor is $\\gamma.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 2.}$\n",
    "As always, we strive to find the Optimal Value Function. The\n",
    "first step in determining the Optimal Value Function is to write\n",
    "the Bellman Optimality Equation.\n",
    "\n",
    "Answer: $V^\\pi(t,W_t)=E_\\pi[\\gamma^{T-t}U(W_T)|(t,W_T)] = E_\\pi[-\\gamma^{T-t}\\frac{e^{-aW_T}}{a}|(t,W_t)].$\n",
    "\n",
    "So the optimality is $V^*(t,W_t) = max_\\pi V^\\pi(t,W_t) = max_{x_t}(E_{R\\sim N(\\mu,\\sigma^2)}[\\gamma V_*(t+1,W_{t+1})])$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 3.}$\n",
    "Assume the functional form for the Optimal Value Function is $-b_t e^{-c_tW_t}$where $b_t$, $c_t$ are unknowns functions of only $t$. Express the Bellman Optimality Equation using this functional form for the Optimal Value Function.\n",
    "\n",
    "Answer: $V^*(t,W_t) = max_{x_t}(E_{R\\sim N(\\mu,\\sigma^2)}[\\gamma V_*(t+1,W_{t+1})]) = max_{x_t}(E_{R\\sim N(\\mu,\\sigma^2)} -\\gamma b_{t+1}e^{-c_t(x_t(1+R)+(W_t-x_t)(1+r))}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 4.}$\n",
    "Since the right-hand-side of the Bellman Optimality Equation\n",
    "involves a max over xt, we can say that the partial derivative of\n",
    "the term inside the max with respect to $x_t$ is 0. This enables us\n",
    "to write the Optimal Allocation $x_t^*$ in terms of $c_{t+1}$.\n",
    "\n",
    "Answer: We want $\\frac{\\partial {V^*(t,W_t)}}{\\partial{x_t}}=0.$ So $-c_{t+1}(\\mu-r)+\\sigma^2c_{t+1}^2x_t^{*} = 0.$ Then we can get $x^* = \\frac{\\mu-r}{\\sigma^2c_{t+1}}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 5.}$\n",
    "Substituting this maximizing $x_t^*$ in the Bellman Optimality Equation enables us to express $b_t$ and $c_t$ as recursive equations in terms of $b_{t+1}$ and $c_{t+1}$ respectively.\n",
    "\n",
    "Answer: $V^*(t,W_t) = -\\gamma b_{t+1}e^{-c_{t+1}W_t(1+r)-\\frac{(\\mu-r)^2}{2\\sigma^2}}.$ And we know $V^*(t,W_t) = -b_t e^{-c_tW_t}.$ So $b_t = \\gamma b_{t+1}e^{-\\frac{(\\mu-r)^2}{2\\sigma^2}}$ and $c_t = c_{t+1}(1+r).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\textbf{Question 6.}$\n",
    "We know $b_T$ and $c_T$ from the knowledge of the MDP Reward at $t = T$ (Utility of Terminal Wealth), which enables us to unroll the above recursions for $b_t$ and $c_t$.\n",
    "\n",
    "$V^*(T, W_T) = -\\frac{e^{-aW_T}}{a}$ so $b_T = 1/a,$ $c_T = a.$ So $b_t = \\frac{\\gamma^{T-t}}{a}e^{-\\frac{(T-t)(\\mu-r)^2}{2\\sigma^2}}$, $c_t = a(1+r)^{T-t}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 7.}$\n",
    "Solving $b_t$ and $c_t$ yields the Optimal Policy and the Optimal Value\n",
    "Function.\n",
    "\n",
    "Plug in $b_t$ and $c_t$: $V^*(t,W_t) = -b_t e^{-c_tW_t} = -\\frac{\\gamma^{T-t}}{a}e^{-\\frac{(T-t)(\\mu-r)^2}{2\\sigma^2}} e^{-a(1+r)^{T-t}W_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
